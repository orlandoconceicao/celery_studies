-Rodar Django
    python manage.py runserver

-Rodar Worker
    Em outro terminal:
        celery -A meu_projeto worker --loglevel=info
    Se aparecer:
        Ready.
    Está funcionando.

- Monitoramento com Flower
    Rodar:
        celery -A meu_projeto flower

===========================================
GUIA COMPLETO DE ESTUDO - CELERY + DJANGO
===========================================

ESTRUTURA DO PROJETO

meu_projeto/
│
├── meu_projeto/
│   ├── __init__.py
│   ├── settings.py
│   ├── celery.py
│
├── usuarios/
│   ├── views.py
│   ├── tasks.py
│
└── manage.py


==================================================
1) ARQUIVO: meu_projeto/celery.py
==================================================

import os
from celery import Celery

os.environ.setdefault("DJANGO_SETTINGS_MODULE", "meu_projeto.settings")

app = Celery("meu_projeto")

app.config_from_object("django.conf:settings", namespace="CELERY")

app.autodiscover_tasks()


EXPLICAÇÃO:

• os → permite acessar variáveis de ambiente.
• Celery → classe principal que cria a aplicação Celery.
• DJANGO_SETTINGS_MODULE → informa ao Celery onde está o settings.py.
• Celery("meu_projeto") → nome da aplicação (usado no comando -A).
• config_from_object → carrega todas as configs que começam com CELERY_.
• autodiscover_tasks() → procura automaticamente arquivos tasks.py.


==================================================
2) ARQUIVO: meu_projeto/__init__.py
==================================================

from .celery import app as celery_app

__all__ = ("celery_app",)


EXPLICAÇÃO:

• Garante que o Celery seja carregado quando o Django iniciar.
• Sem isso, as tarefas podem não ser registradas.


==================================================
3) ARQUIVO: settings.py
==================================================

CELERY_BROKER_URL = "redis://localhost:6379/0"
CELERY_RESULT_BACKEND = "redis://localhost:6379/0"

CELERY_ACCEPT_CONTENT = ["json"]
CELERY_TASK_SERIALIZER = "json"
CELERY_RESULT_SERIALIZER = "json"

CELERY_TIMEZONE = "UTC"


EXPLICAÇÃO:

• Broker = intermediário (Redis).
• Redis porta 6379 banco 0.
• RESULT_BACKEND = onde o resultado da tarefa é salvo.
• ACCEPT_CONTENT = aceita apenas JSON (segurança).
• SERIALIZER = converte Python ↔ JSON.
• TIMEZONE = fuso horário para tarefas agendadas.


==================================================
4) ARQUIVO: usuarios/tasks.py
==================================================

from celery import shared_task
import requests

@shared_task(bind=True, max_retries=3)
def enviar_email_usuario(self, usuario_id):
    try:
        print(f"Processando usuário {usuario_id}")

        resposta = requests.get("https://httpbin.org/get")

        return {
            "status": "sucesso",
            "usuario": usuario_id
        }

    except Exception as e:
        raise self.retry(exc=e, countdown=5)


EXPLICAÇÃO:

• shared_task → registra a função como tarefa do Celery.
• bind=True → permite acessar self.
• max_retries=3 → tenta novamente até 3 vezes.
• self.retry() → se falhar, espera 5 segundos e tenta de novo.
• Ideal para APIs externas, pagamentos, envio de email.


==================================================
5) ARQUIVO: usuarios/views.py
==================================================

from django.http import JsonResponse
from .tasks import enviar_email_usuario

def enviar_email(request):

    enviar_email_usuario.apply_async(
        args=[1],
        countdown=30
    )

    return JsonResponse({"mensagem": "Tarefa agendada"})


EXPLICAÇÃO:

• apply_async() → versão avançada do delay().
• args=[1] → 1 vira o parametro usuario_id.
• countdown=30 → executa após 30 segundos.


==================================================
FLUXO COMPLETO DO SISTEMA
==================================================

1) View chama apply_async()
2) Celery serializa a tarefa
3) Envia para o Redis (Broker)
4) Worker pega da fila
5) Executa
6) Se falhar → retry automático
7) Salva resultado


==================================================
PAPEL DE CADA ARQUIVO
==================================================

celery.py   → Inicializa Celery
__init__.py → Conecta Celery ao Django
settings.py → Configura Redis
tasks.py    → Define tarefas e retry
views.py    → Dispara tarefas


==================================================
ARQUITETURA PROFISSIONAL
==================================================

Producer → Django
Broker   → Redis
Consumer → Worker

Esse padrão é chamado de sistema distribuído baseado em filas.


==================================================
COMANDO PARA RODAR WORKER
==================================================

celery -A meu_projeto worker --loglevel=info


==================================================
CONCEITOS DOMINADOS
==================================================

✔ Integração Celery + Django
✔ Broker
✔ Worker
✔ Retry automático
✔ Serialização
✔ apply_async()
✔ Arquitetura distribuída

https://github.com/orlandoconceicao/celery_studies.git